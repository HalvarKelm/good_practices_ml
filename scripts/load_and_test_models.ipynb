{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./..')\n",
    "from models.region_loss import Regional_Loss\n",
    "from scripts import load_dataset\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from create_datasets_from_embddings import create_datasets_from_embddings\n",
    "from models import nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3634239525.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[50], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    writer.add_scalar(f'{name} avg Class F1', per_clwriter = SummaryWriter(\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def add_metrics_and_plot_tb(criterion,writer, outputs, targets, name, step, training_dataset_name, seed, starting_regional_loss_portion, regional_loss_decline, timestamp):\n",
    "        per_class_precision, per_class_recall, per_class_f1, _, target_idx = criterion.calculate_metrics_per_class(outputs, targets)\n",
    "        writer.add_scalar(f'{name} avg Class Precision', per_class_precision.mean(), step)\n",
    "        writer.add_scalar(f'{name} avg Class Recall', per_class_recall.mean(), step)\n",
    "        writer.add_scalar(f'{name} avg Class F1', per_clwriter = SummaryWriter(\n",
    "            log_dir=f'runs/seed_{seed}/{training_dataset_name[:-4]}/starting_regional_loss_portion-{starting_regional_loss_portion}/regional_loss_decline-{regional_loss_decline}/{timestamp}')ass_f1.mean(), step)\n",
    "\n",
    "        metrics_df = pd.DataFrame({'Precision': per_class_precision, 'Recall': per_class_recall, 'Fscore': per_class_f1})\n",
    "        metrics_df.index = target_idx\n",
    "        \n",
    "        ignored_classes = metrics_df[(metrics_df['Precision'] == 0) & (metrics_df['Recall'] == 0)]\n",
    "        metrics_df = metrics_df.drop(ignored_classes.index)\n",
    "\n",
    "        bar_plot = metrics_df.plot(kind='bar', xlabel='Class', ylabel='Metrics', title='Metrics per Country, {len(ignored_classes)} ignored countries.').get_figure()\n",
    "        writer.add_figure(f'{name} Metrics per Country', bar_plot, step)\n",
    "        writer.add_scalar(f'{name} Number of Ignored Classes', len(ignored_classes), step)\n",
    "\n",
    "        # Calculate metrics per region\n",
    "        per_region_precision, per_region_recall, per_region_f1, _, region_index = criterion.calculate_metrics_per_region(outputs, targets)\n",
    "        writer.add_scalar(f'{name} avg Region Precision', per_region_precision.mean(), step)\n",
    "        writer.add_scalar(f'{name} avg Region Recall', per_region_recall.mean(), step)\n",
    "        writer.add_scalar(f'{name} avg Region F1', per_region_f1.mean(), step)\n",
    "        region_metrics_df = pd.DataFrame({'Precision': per_region_precision, 'Recall': per_region_recall, 'Fscore': per_region_f1})\n",
    "\n",
    "\n",
    "        region_metrics_df.index = region_index\n",
    "        \n",
    "        ignored_regions = region_metrics_df[(region_metrics_df['Precision'] == 0) & (region_metrics_df['Recall'] == 0)]\n",
    "        region_metrics_df = region_metrics_df.drop(ignored_regions.index)\n",
    "\n",
    "        region_bar_plot = region_metrics_df.plot(kind='bar', xlabel='Region', ylabel='Metrics', title=f'Metrics per Region, {len(ignored_regions)} ignored regions.').get_figure()\n",
    "        writer.add_figure(f'{name} Metrics per Region', region_bar_plot, step)\n",
    "        writer.add_scalar(f'{name} Number of Ignored Regions', len(ignored_regions), step)\n",
    "        writer.add_text(f'{name} List of Ignored Regions', ';'.join(ignored_regions.index.to_list()), step)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [4808,4947,5723,3838,5836,3947,8956,5402,1215,8980]\n",
    "training_datasets = [\n",
    "        'geo_weakly_balanced',\n",
    "        'geo_unbalanced',\n",
    "        'geo_strongly_balanced',\n",
    "        'mixed_weakly_balanced',\n",
    "        'mixed_strongly_balanced'\n",
    "    ]\n",
    "hyperparameters = [\n",
    "            'starting_regional_loss_portion-0.0',\n",
    "            'starting_regional_loss_portion-0.25',\n",
    "            'starting_regional_loss_portion-0.8',\n",
    "            'starting_regional_loss_portion-0.5',\n",
    "        ]\n",
    "saved_modesl_path = \"/home/lbrenig/Documents/Uni/GPML/good_practices_ml/saved_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'method'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m model_paths[counter]\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mFinetunedClip()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n",
      "File \u001b[0;32m~/Documents/Uni/GPML/good_practices_ml/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2104\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \n\u001b[1;32m   2071\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2106\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2107\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'method'>."
     ]
    }
   ],
   "source": [
    "\n",
    "REPO_PATH = '/home/lbrenig/Documents/Uni/GPML/good_practices_ml'\n",
    "country_list = f'{REPO_PATH}/country_list/country_list_region.csv'\n",
    "region_list = f'{REPO_PATH}/country_list/UNSD_Methodology.csv'\n",
    "\n",
    "\n",
    "\n",
    "testing_directory = f'{REPO_PATH}/Embeddings/Testing'\n",
    "\n",
    "model_paths = glob.glob('/home/lbrenig/Documents/Uni/GPML/good_practices_ml/saved_models/*epoch_15*')\n",
    "model_paths = [path for path in model_paths if int(path.split(\"_\")[-4][-2:]) > 7]\n",
    "model_paths = sorted(model_paths, key=lambda path: int(''.join(path.split(\"_\")[-4:-3])))\n",
    "\n",
    "counter = 0\n",
    "country_list = pd.read_csv(country_list)\n",
    "criterion = Regional_Loss(country_list)\n",
    "for seed in seeds:\n",
    "    #reate_datasets_from_embddings(seed=seed,REPO_PATH=REPO_PATH)\n",
    "    test_df = pd.read_csv(f'{testing_directory}/knwon_test_data.csv')\n",
    "    test_dataset = load_dataset.EmbeddingDataset_from_df(\n",
    "    test_df, \"test\")\n",
    "    for dataset in training_datasets:\n",
    "        for hyperparameter in hyperparameters:\n",
    "            path = model_paths[counter]\n",
    "            model = nn.FinetunedClip()\n",
    "            model.load_state_dict(torch.load(path))\n",
    "            model.eval()\n",
    "            torch.manual_seed(seed)\n",
    "            writer = SummaryWriter(\n",
    "            log_dir=f'runs/test_experiment1/seed_{seed}/{dataset}/starting_regional_loss_portion-{hyperparameter}/regional_loss_decline-/{1515}')\n",
    "            inputs, targets = test_dataset[:]\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            avg_test_region_accuracy = criterion.claculate_region_accuracy(\n",
    "                outputs, targets)\n",
    "            avg_test_accuracy = criterion.calculate_country_accuracy(\n",
    "                outputs, targets)\n",
    "            \n",
    "            writer.add_scalar(\n",
    "                'Test Accuracy', avg_test_accuracy, )\n",
    "            writer.add_scalar('Test Regional Accuracy',\n",
    "                                avg_test_region_accuracy)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predicitions_idx = torch.argmax(outputs, axis=1).tolist()\n",
    "                target_idx = [country_list[country_list['Country'] == target].index[0] for target in targets]\n",
    "                \n",
    "                try:\n",
    "                    add_metrics_and_plot_tb(criterion,writer, outputs, targets, 'Test', 0, dataset, seed, hyperparameter, 0, '1515')\n",
    "                except Exception as e:\n",
    "                    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
